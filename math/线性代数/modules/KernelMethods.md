# 核方法（Kernel Methods）与“核函数判定链路”

## 1. 一句话
- 核方法把“非线性问题”变成“某个高维特征空间里的线性问题”，靠的是：你只需要算内积 `<φ(x),φ(y)>`，而不需要显式写出 `φ(x)`。

## 2. 核函数（PSD kernel）的定义（最重要）
给定集合 `X`。一个函数 `k: X×X -> R` 称为 **核函数/正半定核（PSD kernel）**，如果对任意 `n` 和任意点 `x_1,...,x_n ∈ X`，构造 Gram 矩阵
- `K ∈ R^{n×n}`, `K_{ij} := k(x_i, x_j)`

都有
- `K \succeq 0`（半正定；见 `math/线性代数/modules/PSD.md`）

等价地：对任意 `c∈R^n`，
- `c^T K c = Σ_{i,j=1}^n c_i c_j k(x_i,x_j) ≥ 0`

> 实数情形通常还要求对称：`k(x,y)=k(y,x)`（否则 `K` 不一定对称）。

## 3. 证明链路
要证明某个候选 `k(x,y)` 是核函数，按下面链路做即可：

1) **任取有限点集**：取任意 `x_1,...,x_n`
2) **写出 Gram 矩阵**：`K_{ij}=k(x_i,x_j)`
3) **证明 `K` 是 PSD**：对任意 `c∈R^n`，证明 `c^T K c ≥ 0`
4) **结论**：因为点集任意，所以 `k` 是 PSD kernel（核函数）

其中第 3 步通常用“把 `c^T K c` 变成某个范数平方/平方和/积分”来做。

## 4. 最常用的证明套路（你以后会反复用）
### 4.1 直接构造特征映射 `φ`（最干净）
如果你能找到某个内积空间 `H` 和映射 `φ: X -> H` 使得
- `k(x,y) = <φ(x), φ(y)>_H`

那么对任意点集，`K` 就是 `φ(x_i)` 的 Gram 矩阵，所以自动 PSD（见 `math/线性代数/modules/PSD.md` 第 5 节）。

### 4.2 用“闭包性质”拼出来（省证明）
若 `k1,k2` 都是核，则：
- `a k1 + b k2` 也是核（`a,b≥0`）
- `k(x,y) = f(x)f(y)` 是核（Gram 矩阵是秩 1：`K=uu^T`）
- `k(x,y) = k1(x,y)·k2(x,y)` 也是核（对应 `K = K1 \odot K2`，用 Schur 乘积定理）

### 4.3 积分表示（把“≥0”变显然）
若能写成
- `k(x,y) = ∫ φ_ω(x) φ_ω(y) dμ(ω)`，其中 `μ` 是非负测度

则
- `c^T K c = ∫ (Σ_i c_i φ_ω(x_i))^2 dμ(ω) ≥ 0`

## 5. 例子（顺手练“链路”）
### 5.1 线性核
- `k(x,y)=x^T y`（`x,y∈R^d`）

对点集 `x_1,...,x_n`，令数据矩阵 `X` 的第 `i` 行是 `x_i^T`，则
- `K_{ij}=x_i^T x_j`，因此 `K = X X^T \succeq 0`

### 5.2 多项式核（整数次数）
- `k(x,y) = (x^T y + c)^p`，其中 `c≥0`、`p∈N`

思路：`(x^T y + c)` 本身是核（线性核 + 常数核），而“核的点乘”仍是核；把 `(·)^p` 看成做 `p` 次点乘即可。

## 6. 核方法里你真正做的线代
- 组 Gram 矩阵 `K`（`K_{ij}=k(x_i,x_j)`）
- 做 PSD/特征值检查（数值上可能出现很小的负特征值：通常是误差）
- 解线性方程/特征分解：
  - Kernel ridge regression：`(K + λI)α = y`
  - Kernel PCA：对居中后的 `K` 做特征分解

## 7. 往泛函分析走一步（可选）
每个 PSD kernel 都对应一个 RKHS（再生核希尔伯特空间）；这是“核=内积”的抽象化版本，后续如果要系统写，可接到 `math/泛函/`。
